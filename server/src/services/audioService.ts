import * as grpc from "@grpc/grpc-js";
import { v4 as uuidv4 } from "uuid";
import { synthesizeSpeech } from "./textToSpeechService";
import { convertSpeechToTextStream } from "./speechToTextService";
import { getAgentSpeechConfig, getAgentData, saveSessionData, getSessionData } from "./firestoreService";
import { generatePrompt } from "./vertexAIService";
import { PassThrough } from "stream";

/**
 * InitializeSession: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒ å¯¾å¿œï¼‰
 */
export const initializeSession = async (
  call: grpc.ServerWritableStream<any, any>
): Promise<void> => {
  try {
    const { agentId, userId } = call.request;
    const sessionId = uuidv4();

    // åˆå›ã®è³ªå•ã‚’ç”Ÿæˆ
    const initialPrompt = `ã“ã‚“ã«ã¡ã¯ã€‚é¢æ¥ã‚’å§‹ã‚ã¾ã™ã€‚å›ç­”ã¯1åˆ†ä»¥å†…ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚ã¾ãšã¯ã€è‡ªå·±ç´¹ä»‹ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚`;

    // Firestoreã‹ã‚‰éŸ³å£°è¨­å®šã‚’å–å¾—
    console.log("Fetching text-to-speech config for the agent...");
    const rawTtsConfig = await getAgentSpeechConfig(agentId);

    const ttsConfig = {
      ssmlGender: mapSsmlGender(rawTtsConfig.ssmlGender),
      name: rawTtsConfig.name,
      speakingRate: rawTtsConfig.speakingRate,
      pitch: rawTtsConfig.pitch,
    };
    
    console.log("Processed text-to-speech config:", ttsConfig);

    // åˆå›ã®éŸ³å£°ã‚’åˆæˆ
    const initialAudio = await synthesizeSpeech(initialPrompt, ttsConfig);

    // Firestoreã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    await saveSessionData(sessionId, agentId, userId, 1, [
      { role: "interviewer", message: initialPrompt },
    ]);

    // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€ä¿¡
    call.write({ sessionId, initialAudioData: initialAudio });
    call.end(); // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‰ã˜ã‚‹
  } catch (error) {
    console.error("Error initializing session:", error);
    call.destroy();
  }
};

/**
 * ProcessAudio: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§å‡¦ç†
 */
export const processAudio = async (call: grpc.ServerDuplexStream<any, any>): Promise<void> => {
  try {
    let sessionId: string = "";
    let agentId: string = "";
    let userId: string = "";
    let currentRound: number = 0;
    let firstChunkReceived = false; // åˆå›ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†æ¸ˆã¿ã‹ã©ã†ã‹

    const audioStream = new PassThrough();
    console.log("ğŸŸ  [DEBUG] Creating audioStream (PassThrough) for STT");

    const textPromise = convertSpeechToTextStream(audioStream); // STTã®éåŒæœŸå‡¦ç†ã‚’é–‹å§‹
    console.log("ğŸŸ  [DEBUG] convertSpeechToTextStream called");

    call.on("data", (request) => {
      if (!sessionId) {
        sessionId = request.sessionId;
        agentId = request.agentId;
        userId = request.userId;
        currentRound = request.currentRound;
        firstChunkReceived = true;

        console.log(`ğŸ”µ [RECEIVE] Start processing sessionId: ${sessionId}, agentId: ${agentId}, userId: ${userId}, currentRound: ${currentRound}`);
      }
    
      if (request.audioData) {
        console.log(`ğŸŸ¡ [RECEIVE] Received audio chunk - Size: ${request.audioData.length} bytes`);
        console.log(`ğŸŸ¡ [RECEIVE] Chunk Preview (hex): ${request.audioData.slice(0, 10).toString("hex")}`);

        // `audioData` ã®ã¿ã‚’ STT ã«é€ä¿¡
        audioStream.write(request.audioData);
        console.log(`ğŸŸ¢ [STREAM] Sent chunk to STT - Size: ${request.audioData.length} bytes`);
      }
    });

    call.on("end", async () => {
      try {
        console.log("ğŸŸ  [END] Received all chunks. Closing stream.");
        audioStream.end(); // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®çµ‚äº†ã‚’æ˜ç¤º
        console.log("Streaming audio received completely, processing text...");

        // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å—ä¿¡ã—ã¦ã„ãŸå¤‰æ›çµæœã‚’å–å¾—
        const userText = await textPromise;
        console.log(`ğŸ”´ [FINAL] Final transcription: ${userText}`);

        // Firestoreã‹ã‚‰éå»ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
        const sessionData = await getSessionData(sessionId);
        const conversationHistory = sessionData?.conversationHistory || [];

        // Firestoreã«ãƒ¦ãƒ¼ã‚¶ã®ç™ºè¨€ã‚’ä¿å­˜
        conversationHistory.push({ role: "interviewee", message: userText });

        await saveSessionData(sessionId, agentId, userId, currentRound + 1, conversationHistory);

        // Firestoreã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        const agentData = await getAgentData(agentId);
        if (!agentData) {
          throw new Error(`Agent data not found for agentId: ${agentId}`);
        }

        const maxRounds = agentData.maxRounds || 6;
        const promptType: "interview" | "feedback" = currentRound === maxRounds ? "feedback" : "interview";

        // Geminiã§æ¬¡ã®è³ªå•ã¾ãŸã¯ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
        const nextPrompt = await generatePrompt(agentId, conversationHistory, userText, currentRound, promptType);

        // Firestoreã‹ã‚‰éŸ³å£°è¨­å®šã‚’å–å¾—
        const rawTtsConfig = await getAgentSpeechConfig(agentId);
        const ttsConfig = {
          ssmlGender: mapSsmlGender(rawTtsConfig.ssmlGender),
          name: rawTtsConfig.name,
          speakingRate: rawTtsConfig.speakingRate,
          pitch: rawTtsConfig.pitch,
        };

        // æ¬¡ã®è³ªå•ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã€éŸ³å£°åŒ–&ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜
        let audioResponse: Buffer;

        if (promptType === "feedback") {
          try {
            // ä¸è¦ãªæ–‡å­—åˆ—ã‚’å‰Šé™¤ã™ã‚‹
            const sanitizedPrompt = nextPrompt
            .replace(/```json/g, "") // ` ```json ` ã‚’å‰Šé™¤
            .replace(/```/g, "") // ` ``` ` ã‚’å‰Šé™¤
            .trim();

            const feedback = JSON.parse(sanitizedPrompt);

            if (
              feedback.feedback &&
              feedback.feedback.good_points &&
              feedback.feedback.good_points.detailed &&
              feedback.feedback.good_points.summary &&
              feedback.feedback.improvement_points &&
              feedback.feedback.improvement_points.detailed &&
              feedback.feedback.improvement_points.summary &&
              typeof feedback.feedback.evaluationScore === "number" &&
              feedback.feedback.evaluationReason &&
              feedback.feedback.passOrFail &&
              feedback.feedback.reason
            ) {
              const speechText = `ã§ã¯é¢æ¥ã‚’çµ‚äº†ã—ã¾ã™ã€‚ã“ã‚Œã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã„ãŸã—ã¾ã™ã€‚ã‚ˆã‹ã£ãŸç‚¹ã€‚${feedback.feedback.good_points.summary}ã€‚æ”¹å–„ç‚¹ã€‚${feedback.feedback.improvement_points.summary}ã€‚`;

              // ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯éŸ³å£°åŒ–
              audioResponse = await synthesizeSpeech(speechText, ttsConfig);

              // Firestoreã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æƒ…å ±ã‚’ä¿å­˜
              const feedbackData = {
                good_points_detailed: feedback.feedback.good_points.detailed,
                good_points_summary: feedback.feedback.good_points.summary,
                improvement_points_detailed: feedback.feedback.improvement_points.detailed,
                improvement_points_summary: feedback.feedback.improvement_points.summary,
                evaluationScore: feedback.feedback.evaluationScore,
                evaluationReason: feedback.feedback.evaluationReason,
                passOrFail: feedback.feedback.passOrFail,
                reason: feedback.feedback.reason,
              };
              console.log("Saving feedback to Firestore...", feedbackData);
              // `saveSessionData`ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ä¿å­˜
              await saveSessionData(
                sessionId,
                agentId,
                userId,
                currentRound + 1,
                conversationHistory,
                feedbackData // ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™
              );
            } else {
              throw new Error("Invalid feedback format.");
            }
          } catch (error) {
            console.error("Error processing feedback JSON:", error);
            throw new Error("Failed to process feedback data.");
          }
        } else { 
          // æ¬¡ã®è³ªå•ã®éŸ³å£°åŒ–
          audioResponse = await synthesizeSpeech(nextPrompt, ttsConfig);

          // é€šå¸¸ã®å‡¦ç†: é¢æ¥å®˜ã®æ¬¡ã®è³ªå•ã‚’è¿½åŠ ã—ã¦ä¿å­˜
          conversationHistory.push({ role: "interviewer", message: nextPrompt });
          await saveSessionData(sessionId, agentId, userId, currentRound + 1, conversationHistory);
          console.log("Conversation history saved successfully.");
        }

        // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§éŸ³å£°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é€ä¿¡
        call.write({ audioData: audioResponse });

        console.log("Streaming response sent successfully.");
        call.end();
      } catch (error) {
        console.error("Error processing audio:", error);
        call.destroy();
      }
    });

    // STTã®çµæœã‚’å¾…ã¤
    const transcribedText = await textPromise;
    console.log(`ğŸ”´ [STT FINAL] Transcription result: "${transcribedText}"`);

    // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¨ãƒ©ãƒ¼å‡¦ç†
    call.on("error", (error) => {
      console.error("âŒ [ERROR] Streaming error:", error);
      call.destroy(error);
    });
  } catch (error) {
    console.error("âŒ [ERROR] processAudio failed:", error);
    call.destroy();
  }
};


/**
 * ssmlGender ã‚’å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
 */
import { protos } from "@google-cloud/text-to-speech";
const mapSsmlGender = (gender: string): protos.google.cloud.texttospeech.v1.SsmlVoiceGender => {
  switch (gender.toUpperCase()) {
    case "MALE":
      return protos.google.cloud.texttospeech.v1.SsmlVoiceGender.MALE;
    case "FEMALE":
      return protos.google.cloud.texttospeech.v1.SsmlVoiceGender.FEMALE;
    case "NEUTRAL":
    default:
      return protos.google.cloud.texttospeech.v1.SsmlVoiceGender.NEUTRAL;
  }
};
